'''
Arthor:      Yu-Hsuan Tseng
Date:        02/03/2017
Description: This file contains the specific functions
             for hotspot for train_dnn.py

loss: calculates the loss for NN to minimize
training: defines the training method
evaluation: calculates the accuracy
'''
import tensorflow as tf

def loss(outputs, goldens):
    '''calculates the loss from outputs and goldens

    Args:
        outputs: [batch_size, 1] generated by NN
        goldens: [batch_size, 1] golden outputs

    Returns:
        loss: loss tensor of type float
    '''
    return tf.reduce_mean(tf.abs(tf.sub(outputs, goldens)))
    #return tf.reduce_mean(tf.square(tf.sub(outputs, goldens)))

def training(loss, learning_rate):
    '''sets up the traing ops
    creates a summarizer to track the loss over time in TensorBoard
    creates an optimizer

    Args:
        loss: loss tensor, from loss()
        learning_rate: learning rate

    Return:
        train_op: the op that must be passed to the 'sess.run()'
        to cause the model to train
    '''
    # summarizer, not necessary
    tf.summary.scalar('loss', loss)
    # TODO: optimizer can be modified
    optimizer = tf.train.AdagradOptimizer(learning_rate)
    # op
    train_op = optimizer.minimize(loss)
    return train_op

def error(outputs, goldens):
    '''accumulate the error within one batch of data

    Args:
        outputs: [batch_size, 1] generated by NN
        goldens: [batch_size, 1] golden outputs

    Returns:
        error: the sum of error in one batch of data
    '''
    return tf.reduce_sum(tf.abs(tf.div(tf.sub(outputs, goldens), goldens)))
    #return tf.reduce_sum(tf.square(tf.div(tf.sub(outputs, goldens), goldens)))
